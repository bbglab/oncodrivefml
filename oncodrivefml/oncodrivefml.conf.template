[genome]
# Build of the reference genome
# Currently supported: hg19, hg38 and hg18
build = 'hg19'



[signature]

# Choose the method to calculate the trinuclotide singature:

# "full" : Use a 192 matrix with all the possible signatures
method = 'full'

# "complemented" : Use a 96 matrix with the signatures complemented
# method = 'complement'

# "none": Don't use signature
# method = 'none'

# "bysample": Compute a 96 matrix signature for each sample
# method = 'bysample'

# "file": Provide a file with the signature to use
# The format is a tab separated file with header, and you have to set the columns to use.
# method = 'file'
# path = [path to the file that contains the signature]
# column_ref = [column that contains the reference signature]
# column_alt = [column that contains the alternate signature]
# column_probability = [column that contaions the probability]


# Choose the classifier for the signature:

# you can use any of the columns in the dataset
# classifier = SAMPLE
# classifier = CANCER_TYPE

# or leave it empty to use the whole dataset


# Include/exclude MNP mutations in the signature computation
include_mnp = True
# include_mnp = False


# Choose if the signature must be computed using the whole cohort or
# only the elements that fall into the regions you are analysing:
only_mapped_mutations = False
# only_mapped_mutations = True


# The frequency of trinucleotides can be normalized by the frequency of sites

# whole_genome/wgs: correct the signature for the whole genome frequencies
# normalize_by_sites = 'whole_genome'

# whole_exome/wxs/wes: correct the signature for frequencies in coding regions
# correct_signature_by_sites = 'whole_exome'

# None: do not correct (comment the option)
# normalize_by_sites = ''



[score]
# Path to score file
file = "%(bgdata://genomicscores/cadd/1.0)"
# WARNING: The %(bgdata:...) will download (the first time that you use it) a score file from
# our servers and install it into the ~/.bgdata folder.

# WARNING: CADD 1.0 scores are original from http://cadd.gs.washington.edu/ and are freely
# available for all non-commercial applications. If you are planning on using them in a
# commercial application, please contact them at http://cadd.gs.washington.edu/contact.

# Format of the file
# 'tabix': tab separated file compress with bgzip and next to a Tabix .tbi index file
format = 'tabix'

# Column that has the chromosome
chr = 0

# If the chromosome has a prefix like 'chr'. Example: chrX chr1 ...
chr_prefix = ''

# Column that has the position
pos = 1

# Column that has the reference allele
ref = 2

# Column that has the alternative allele
alt = 3

# Column that has the score value
score = 5

# If you have different scores at the same position, and each score applies to a
# different region element, then uncomment this line and set the value to the column
# that has the element id to match.
# element = 6

# Minimum number of stops per element to infer a for the stops using the mean of all scores
minimum_number_of_stops = 3

# Function to infer the value of the stops in an element using the mean (x is the mean value of the scores)
mean_to_stop_function = '8.9168668946147314*np.exp(0.082688007694096191*x)'



[statistic]

# Mathematical method to use to compare observed and simulated values
# Arithmetic mean
method = amean

# Gemoetric mean
# method = gmean

# Compute the observed values using only 1 mutation per sample
#per_sample_analysis = 'max'
#per_sample_analysis = 'amean'
#per_sample_analysis = 'gmean'

# Do not use/use MNP mutations in the analysis
discard_mnp = False
#dicard_mnp = True


# Simulate mutations according to probabilites observed in the whole cohort
# or in each individual region
cohort_probabilities = True
# cohort_probabilities = False


# Minimum sampling
sampling = 100000

# Maximum sampling
sampling_max = 1000000

# Sampling chunk
sampling_chunk = 100000000

# Minimum number of observed (if not reached, keeps computing)
sampling_min_obs = 3


[[indels]]
# Include/exclude indels from your analysis
include = True
# include = False

# Method used to simulate indels

# Treat them as stops (for coding regions)
# method = 'stop'

# Treat them as a set of substitutions and take the maximum
# method = 'max'

# Number of consecutive times the indel appears to consider it falls in a repetitive region
# Looking from the indel position and in the direction of the strand
max_consecutive = 7

# Do not discard indels that fall in repetitive regions
# max_consecutive = 0

# Function applied to the scores of the stops in the gene to compute the observed score

# Arithmetic mean
stops_function = 'mean'

# Median
# stops_function = 'median'

# Random value between the max and the minimum
# stops_function = 'random'

# Random choice amongst the values
# stops_function = 'random_choice'

# Indels simulated as substitutions take into account signature or not
simulate_with_signature =  True
# simulate_with_signature = False



[settings]
# Number of cores to use in the analysis
# Comment this option to use all avaliable cores
# cores = 6


# Configuration for the logging system
[logging]
version = 1
disable_existing_loggers = False
[[handlers]]
[[[console]]]
class = 'logging.StreamHandler'
formatter = 'bgformat'
level = 'INFO'
stream = 'ext://sys.stdout'
[[[file]]]
class = 'logging.FileHandler'
formatter = 'bgformat'
filename = 'log.txt'
mode = 'w'
[[formatters]]
[[[bgformat]]]
format ='%(asctime)s %(levelname)s: %(message)s'
datefmt ='%H:%M:%S'
[[loggers]]
[[[oncodrivefml]]]
handlers = ['console', 'file']
level = 'DEBUG'
propagate = 0
